import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
import re
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import f1_score, classification_report, accuracy_score, multilabel_confusion_matrix

nltk.download('stopwords')
from nltk.corpus import stopwords

# 1. Load Data with correct separator
df = pd.read_csv("train_data.txt", sep=":::", engine="python", names=["movie_id", "plot", "genres"])
print("Sample data:")
print(df.head())
print("Shape:", df.shape)

# 2. Preprocessing
def clean_text(text):
    if pd.isnull(text):
        return ""
    text = text.lower()
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    tokens = text.split()
    tokens = [word for word in tokens if word not in stopwords.words('english')]
    return ' '.join(tokens)

df['clean_plot'] = df['plot'].apply(clean_text)
df['genres'] = df['genres'].apply(lambda x: x.split('|') if isinstance(x, str) else [])

# 3. Prepare Features and Labels
mlb = MultiLabelBinarizer()
y = mlb.fit_transform(df['genres'])

vectorizer = TfidfVectorizer(max_features=7000)
X = vectorizer.fit_transform(df['clean_plot'])

# 4. Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 5. Model Selection & Training
models = {
    'Logistic Regression': OneVsRestClassifier(LogisticRegression(max_iter=1000)),
    'Random Forest': OneVsRestClassifier(RandomForestClassifier(n_estimators=100)),
    'Linear SVC': OneVsRestClassifier(LinearSVC())
}

results = {}

for name, model in models.items():
    print(f"\nTraining {name}...")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    f1 = f1_score(y_test, y_pred, average='micro')
    results[name] = f1
    print(f"{name} F1 Score (micro): {f1:.4f}")

print("\nModel comparison (F1 scores):")
for k, v in results.items():
    print(f"{k}: {v:.4f}")

# 6. Final Evaluation on Best Model
best_model_name = max(results, key=results.get)
print(f"\nBest Model: {best_model_name}")
best_model = models[best_model_name]
y_pred = best_model.predict(X_test)

print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=mlb.classes_))

# 7. Feature Importance (for Logistic Regression)
if best_model_name == 'Logistic Regression':
    feature_names = np.array(vectorizer.get_feature_names_out())
    for i, class_label in enumerate(mlb.classes_):
        top = np.argsort(best_model.estimators_[0].coef_[i])[-10:]
        print(f"Top words for genre '{class_label}': {feature_names[top][::-1]}")

# 8. Visualization: Genre Distribution
plt.figure(figsize=(10,6))
genre_counts = df['genres'].explode().value_counts()
sns.barplot(x=genre_counts.index, y=genre_counts.values)
plt.title("Genre Distribution")
plt.ylabel("Count")
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig("genre_distribution.png")
plt.show()
